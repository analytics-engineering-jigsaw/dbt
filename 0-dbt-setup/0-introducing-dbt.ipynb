{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "innocent-enlargement",
   "metadata": {},
   "source": [
    "# Why DBT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assisted-renaissance",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offshore-tomorrow",
   "metadata": {},
   "source": [
    "DBT stands for data build tool, and is used to facilitate a specific component of data engineering: the transform step.  Think back to our ELT pattern.  It involves:\n",
    "\n",
    "1. Extracting data, \n",
    "2. Loading it into an analytical database, and\n",
    "3. Then transforming\n",
    "\n",
    "We already saw how we can extract and load with a tool like Fivetran.  But once our data is loaded, we'll still need to transform our data so it fits a structure more appropriate for analytical databases -- like the star schema.\n",
    "\n",
    "So that's one benefit of DBT - it's beneficial for a ELT workflow.  Here are a couple of other benefits of using DBT.  \n",
    "\n",
    "DBT:\n",
    "\n",
    "1. Brings engineering best practices to previously adhoc queries \n",
    "2. Make these queries simpler to accomplish through automation\n",
    "\n",
    "In this lesson, we'll explore each of these motivations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-retirement",
   "metadata": {},
   "source": [
    "### 1. From ETL to ELT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b2cab1-6429-4191-b096-adc2778d422f",
   "metadata": {},
   "source": [
    "As we know, the original process for moving data into a data warehouse was one of extract transform and load (ETL). With ETL, data is transformed *before* loading it into the analytics database.  And this means that before loading data into the analytics database, engineers would need to determine what data to capture, create tables for just that data, and transform data to be loaded into those tables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coral-scientist",
   "metadata": {},
   "source": [
    "<img src=\"./etl_process.jpg\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rocky-compromise",
   "metadata": {},
   "source": [
    "By contrast, with the ELT pattern, we first load raw data into the data warehouse and then transform it to fit our needs.  \n",
    "\n",
    "We saw extract and loading portion with Fivetran, where we load in our raw data into an analytics database like snowflake.  And from there, we'll need to further transform the data so that it's appropriate for an analytical database.  We can see this process in the diagram below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imported-houston",
   "metadata": {},
   "source": [
    "<img src=\"./elt_para.jpg\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1202b95-3a14-4ea9-8d5c-d5c1f843a439",
   "metadata": {},
   "source": [
    "More and more data pipelines have shifted from a pattern of ETL to ELT."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "white-billion",
   "metadata": {},
   "source": [
    "ELT became more of appealing as storage has become cheaper.  With ELT, the approach is might as well store all of the data.  \n",
    "   \n",
    "And ELT has benefits of ELT as an ELT pattern allows for:\n",
    "    * Exploration and familiarization with the data *before* transforming it to a specific format\n",
    "    * Different stakeholders to acccess and transform the raw data to their particular needs\n",
    "\n",
    "So with ELT the thinking is essentially: just load the data, and we'll figure out how to use it as we go.  This is the extract and load, and then transform pattern in a nutshell.\n",
    "\n",
    "Finally, the ELT pattern brings another benefit: it let's the transformation of the data to occur through knowledge of SQL, and not Python or Fivetran.  And this allows more kinds of employees can perform this transformation request."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pharmaceutical-hardware",
   "metadata": {},
   "source": [
    "### 2. From Adhoc to Organized "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beginning-thing",
   "metadata": {},
   "source": [
    "This move to ELT and ease of transforming data from the data warehouse did come with a downside however, and that's a lack of organization.\n",
    "\n",
    "With more teams being given access to the same original source data, companies found multiple teams performing the same work.\n",
    "\n",
    "And with data, the issues go beyond simply duplicating work through different teams.  We want to make sure different teams are using the same *data definitions* of say, active customers.  And we want to make sure that tests are written to ensure these queries are correct.  And it would even be nice if git was used throughout so that we could track changes to queries over time.  \n",
    "\n",
    "An engineering workflow can solve many of the problems listed above, and as we'll see, DBT makes it easy to introduce testing, consolidate queries, and use a version control system like git and github."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "central-pattern",
   "metadata": {},
   "source": [
    "### 3. Tables on Demand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beneficial-crowd",
   "metadata": {},
   "source": [
    "So we've seen that ELT led to more and more queries of an analytics database.  And we   saw that there became a need to organize these queries.  But there's one other main benefit that DBT provides, and that's the service of easily creating and populating tables:\n",
    "\n",
    "\n",
    "* With DBT, we can run a select statement, and DBT will turn the selected data into a populated table or view.  \n",
    "\n",
    "For example, with DBT, we can issue a select statement for customer's names and birthdays, and DBT will write the SQL to create a new table and insert the data selected into that table.  So we can forget about writing a `CREATE TABLE` statement or an `INSERT INTO` statement.  DBT will write this for us."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integrated-sixth",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "median-support",
   "metadata": {},
   "source": [
    "In this lesson, we saw some of the benefits that are provided by DBT.  The Data Build Tool is an outgrowth of the Extract Load Transform paradigm.  This paradigm allows us to transform data as an isolated step, and as a step that we can properly organize (with the help of DBT).  Organizing this transformation step is necessary to avoid duplicate work, standardize our data and data definitions, and ensure engineering best practices like version control and testing.  Finally, we saw that DBT will also allow us to easily transform a SQL query to a newly created table by helping us to create views. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
